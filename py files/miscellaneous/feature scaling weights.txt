import torch
import torch.nn as nn
import torchvision.models as models
import numpy as np
from skimage.feature import graycomatrix, graycoprops, local_binary_pattern
from skimage.filters import gabor
import pywt
from torchvision.models import swin_t, Swin_T_Weights
import pytorch_lightning as pl
import torch.nn.functional as F
import cv2

def check_gpu_memory():
    if torch.cuda.is_available():
        print(f"GPU Memory Stats:")
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            reserved = torch.cuda.memory_reserved(i) / 1024**3
            print(f"GPU {i}: Allocated {allocated:.2f} GiB, Reserved {reserved:.2f} GiB")

class TextureExtractor:
    def __init__(self, glcm_distances=[1, 2, 3], glcm_angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], lbp_P=24, lbp_R=3, wavelet='db1'):
        self.glcm_distances = glcm_distances
        self.glcm_angles = glcm_angles
        self.lbp_P = lbp_P
        self.lbp_R = lbp_R
        self.wavelet = wavelet
        self.properties = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'correlation']

    def __call__(self, img: np.ndarray) -> np.ndarray:
        # Convert RGB to grayscale if necessary
        if img.ndim == 3 and img.shape[-1] == 3:
            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        elif img.ndim != 2:
            raise ValueError(f"Expected 2D grayscale or 3D RGB image, got shape {img.shape}")

        # Ensure image is uint8
        if img.dtype != np.uint8:
            img = (255 * img).astype(np.uint8)

        # GLCM features
        glcm = graycomatrix(img, distances=self.glcm_distances, angles=self.glcm_angles,
                            levels=256, symmetric=True, normed=True)
        feats_glcm = []
        for prop in self.properties:
            prop_vals = graycoprops(glcm, prop).flatten()
            feats_glcm.extend(prop_vals.tolist())

        # LBP features
        lbp = local_binary_pattern(img, self.lbp_P, self.lbp_R, method='uniform')
        n_bins = self.lbp_P + 2
        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
        feats_lbp = hist.tolist()

        # Gabor features
        feats_gabor = []
        for freq in [0.2, 0.4, 0.6]:
            for theta in [0, np.pi/4, np.pi/2]:
                real, imag = gabor(img, frequency=freq, theta=theta)
                feats_gabor.extend([real.mean(), real.var(), imag.mean(), imag.var()])

        # Wavelet features
        LL, (LH, HL, HH) = pywt.dwt2(img.astype(np.float32), self.wavelet)
        feats_wavelet = [LL.mean(), LH.mean(), HL.mean(), HH.mean(),
                         LL.std(), LH.std(), HL.std(), HH.std()]

        # Combine and return as float32
        features = np.hstack([feats_glcm, feats_lbp, feats_gabor, feats_wavelet]).astype(np.float32)
        if len(features) != 130:
            raise ValueError(f"TextureExtractor produced {len(features)} features, expected 130")
        return features

class HybridClassifierModule(pl.LightningModule):
    def __init__(self, cfg):
        super().__init__()
        self.save_hyperparameters(cfg)

        # Set matmul precision based on config
        if self.hparams.train.test_precision:
            torch.set_float32_matmul_precision('highest')
        else:
            torch.set_float32_matmul_precision('medium')

        # CNN backbone (Swin Transformer Tiny)
        base_cnn = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)
        if self.hparams.train.frozen_layers > 0:
            for param in base_cnn.parameters():
                param.requires_grad = False
            for param in list(base_cnn.layers)[-self.hparams.train.frozen_layers:]:
                param.requires_grad = True
        self.backbone = base_cnn

        # Dropout layer
        self.dropout = nn.Dropout(p=0.6)

        # Texture feature extractor
        self.texture_extractor = TextureExtractor(
            glcm_distances=[1, 2, 3],
            glcm_angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
            lbp_P=24,
            lbp_R=3,
            wavelet='db1'
        )
        
        # Compute actual dimensions dynamically
        dummy_img = np.zeros((224, 224, 3), dtype=np.uint8)
        texture_feats = self.texture_extractor(dummy_img)
        self.texture_feat_len = len(texture_feats)
        
        # Get actual CNN feature size
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 224, 224)
            cnn_output = self.backbone(dummy_input)
            self.cnn_feat_len = cnn_output.view(1, -1).size(1)
        
        print(f"CNN feature length: {self.cnn_feat_len}")
        print(f"Texture feature length: {self.texture_feat_len}")
        
        # Learnable weighting parameters
        self.cnn_weight = nn.Parameter(torch.ones(1))
        self.texture_weight = nn.Parameter(torch.ones(1) * 3.0)  # Give texture features more initial weight
        
        # Classifier
        self.classifier = nn.Sequential(
            nn.Linear(self.cnn_feat_len + self.texture_feat_len, 256),
            nn.ReLU(),
            nn.Dropout(p=0.6),
            nn.Linear(256, self.hparams.model.num_classes)
        )

        # Loss function with label smoothing
        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

    def forward(self, x: torch.Tensor, tex: torch.Tensor = None) -> torch.Tensor:
        if isinstance(x, (list, tuple)):
            x, tex = x[0], x[2] if len(x) > 2 else None

        B = x.size(0)
        feat = self.backbone(x).view(B, -1)
        feat = self.dropout(feat)

        if tex is None:
            imgs = x.detach().cpu().numpy().transpose(0, 2, 3, 1)
            tex_feats = []
            for i in range(B):
                tex_feats.append(self.texture_extractor(imgs[i]))
            tex = torch.from_numpy(np.stack(tex_feats)).to(x.device, dtype=torch.float32)

        # Ensure feature tensors are in the same dtype as the model
        feat = feat.to(dtype=torch.float16 if self.trainer.precision == "16-mixed" else torch.float32)
        tex = tex.to(dtype=torch.float16 if self.trainer.precision == "16-mixed" else torch.float32)
        
        if tex.size(1) != self.texture_feat_len:
            raise ValueError(f"Texture feature length mismatch: expected {self.texture_feat_len}, got {tex.size(1)}")
        
        # SOLUTION 1: Feature Scaling and Weighting
        # Normalize features to unit vectors (L2 normalization)
        feat_norm = F.normalize(feat, p=2, dim=1)
        tex_norm = F.normalize(tex, p=2, dim=1)
        
        # Apply learnable weights
        feat_weighted = feat_norm * self.cnn_weight
        tex_weighted = tex_norm * self.texture_weight
        
        # Alternative: Use batch normalization for automatic scaling
        # feat_bn = F.batch_norm(feat, None, None, training=self.training)
        # tex_bn = F.batch_norm(tex, None, None, training=self.training)
        
        fused = torch.cat([feat_weighted, tex_weighted], dim=1)
        logits = self.classifier(fused)
        
        # Log the learned weights for monitoring
        if self.training:
            self.log("cnn_weight", self.cnn_weight.item(), on_step=False, on_epoch=True)
            self.log("texture_weight", self.texture_weight.item(), on_step=False, on_epoch=True)
        
        return logits

    def training_step(self, batch, batch_idx):
        x, y, tex = batch
        check_gpu_memory()
        logits = self(x, tex)
        loss = self.criterion(logits, y)
        acc = (logits.argmax(dim=1) == y).float().mean()
        self.log("train_loss", loss, on_step=False, on_epoch=True)
        self.log("train_acc", acc, on_step=False, on_epoch=True, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y, tex = batch
        check_gpu_memory()
        logits = self(x, tex)
        loss = self.criterion(logits, y)
        acc = (logits.argmax(dim=1) == y).float().mean()
        self.log("val_loss", loss, on_step=False, on_epoch=True, prog_bar=True)
        self.log("val_acc", acc, on_step=False, on_epoch=True, prog_bar=True)
        return {'val_loss': loss, 'val_acc': acc}

    def test_step(self, batch, batch_idx):
        x, y, tex = batch
        check_gpu_memory()
        logits = self(x, tex)
        loss = self.criterion(logits, y)
        acc = (logits.argmax(dim=1) == y).float().mean()
        self.log("test_loss", loss, on_step=False, on_epoch=True, prog_bar=True)
        self.log("test_acc", acc, on_step=False, on_epoch=True, prog_bar=True)
        return {'test_loss': loss, 'test_acc': acc, 'logits': logits}

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.train.lr, weight_decay=1e-3)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)
        return {
            'optimizer': optimizer,
            'lr_scheduler': {'scheduler': scheduler, 'monitor': 'val_loss'}
        }